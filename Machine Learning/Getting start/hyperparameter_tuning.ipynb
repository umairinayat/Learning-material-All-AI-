{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "Hyperparameter tuning is the process of finding the best hyperparameters for a model. Hyperparameters are the parameters that are not learned by the model, and they are set before the training process. In this notebook, I will show you how to use the `optuna` library to perform hyperparameter tuning for a simple machine learning model.\n",
    "\n",
    "**Types of Hyperparameters**\n",
    "\n",
    "There are two types of hyperparameters:\n",
    "\n",
    "Grid Search: In this method, we define a grid of hyperparameters and then train the model with each combination of hyperparameters. This method is simple but computationally expensive.\n",
    "Random Search: In this method, we define a range of hyperparameters and then train the model with random combinations of hyperparameters. This method is less computationally expensive than grid search.\n",
    "Bayesian Optimization: In this method, we use the results of the previous iterations to select the next hyperparameters to try. This method is more computationally expensive than random search but less computationally expensive than grid search.\n",
    "Gradient-based Optimization: In this method, we use the gradient of the loss function with respect to the hyperparameters to find the best hyperparameters. This method is computationally expensive but can be very effective.\n",
    "\n",
    "**Optuna**\n",
    "\n",
    "Optuna is a hyperparameter optimization framework that is designed for machine learning. It is easy to use and supports various optimization algorithms, including grid search, random search, Bayesian optimization, and gradient-based optimization. In this notebook, I will show you how to use Optuna to perform hyperparameter tuning for a simple machine learning model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation\n",
    "\n",
    "Cross-validation is a technique used to evaluate the performance of a machine learning model. It is used to estimate the performance of a model on an independent dataset. In this notebook, I will show you how to use the `sklearn` library to perform cross-validation for a simple machine learning model.\n",
    "\n",
    "**Types of Cross-Validation**\n",
    "\n",
    "There are several types of cross-validation:\n",
    "\n",
    "**K-Fold Cross-Validation:** In this method, the dataset is divided into k subsets, and the model is trained k times, each time using a different subset as the test set and the remaining subsets as the training set. The performance of the model is then averaged over the k iterations.\n",
    "\n",
    "**Stratified K-Fold Cross-Validation:** In this method, the dataset is divided into k subsets, and the model is trained k times, each time using a different subset as the test set and the remaining subsets as the training set. The performance of the model is then averaged over the k iterations. This method is used when the dataset is imbalanced.\n",
    "\n",
    "**Leave-One-Out Cross-Validation:** In this method, the model is trained k times, each time using all the data except one sample as the training set and the remaining sample as the test set. The performance of the model is then averaged over the k iterations.\n",
    "\n",
    "**Leave-P-Out Cross-Validation:** In this method, the model is trained k times, each time using all the data except p samples as the training set and the remaining p samples as the test set. The performance of the model is then averaged over the k iterations.\n",
    "\n",
    "**Stratified Shuffle Split Cross-Validation:** In this method, the dataset is divided into k subsets, and the model is trained k times, each time using a different subset as the test set and the remaining subsets as the training set. This method is used when the dataset is imbalanced.\n",
    "\n",
    "**Time Series Cross-Validation:** In this method, the dataset is divided into k subsets, and the model is trained k times, each time using a different subset as the test set and the remaining subsets as the training set. This method is used when the dataset is a time series.\n",
    "In this notebook, I will show you how to use the `sklearn` library to perform k-fold cross-validation for a simple machine learning model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 150 candidates, totalling 750 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "250 fits failed out of a total of 750.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "219 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "31 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan 0.95333333\n",
      " 0.96       0.96       0.96666667 0.96       0.96       0.96666667\n",
      " 0.96666667 0.96       0.96666667        nan        nan        nan\n",
      "        nan        nan 0.96       0.96666667 0.96666667 0.96\n",
      " 0.96       0.96       0.96666667 0.96666667 0.96666667 0.96\n",
      "        nan        nan        nan        nan        nan 0.96666667\n",
      " 0.96       0.96666667 0.96666667 0.96       0.95333333 0.96666667\n",
      " 0.96666667 0.96       0.96666667        nan        nan        nan\n",
      "        nan        nan 0.96       0.96666667 0.96666667 0.96\n",
      " 0.96666667 0.96       0.96666667 0.96666667 0.96       0.96\n",
      "        nan        nan        nan        nan        nan 0.96666667\n",
      " 0.96       0.96       0.96666667 0.96666667 0.96666667 0.96\n",
      " 0.96       0.96       0.96              nan        nan        nan\n",
      "        nan        nan 0.96       0.96666667 0.96       0.96666667\n",
      " 0.96       0.96666667 0.96       0.96666667 0.96666667 0.96666667\n",
      "        nan        nan        nan        nan        nan 0.96666667\n",
      " 0.96666667 0.96666667 0.96666667 0.96666667 0.95333333 0.96666667\n",
      " 0.96666667 0.96666667 0.96666667        nan        nan        nan\n",
      "        nan        nan 0.95333333 0.96666667 0.96666667 0.96666667\n",
      " 0.96666667 0.95333333 0.96       0.96       0.96666667 0.96666667\n",
      "        nan        nan        nan        nan        nan 0.96\n",
      " 0.96666667 0.96666667 0.96666667 0.96666667 0.96666667 0.96\n",
      " 0.96       0.96666667 0.96666667        nan        nan        nan\n",
      "        nan        nan 0.96666667 0.96666667 0.96       0.96\n",
      " 0.96666667 0.96666667 0.96666667 0.96666667 0.96       0.96666667]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'n_estimators': 400}\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "para_grid = {'n_estimators': [100, 200, 300, 400, 500],\n",
    "             'max_features': ['auto', 'sqrt', 'log2'],\n",
    "                'max_depth': [10, 20, 30, 40, 50],\n",
    "             'criterion': ['gini', 'entropy']\n",
    "             }\n",
    "\n",
    "# set up the grid\n",
    "grid_model = GridSearchCV(model, \n",
    "                          para_grid, \n",
    "                          cv=5, \n",
    "                          scoring='accuracy',\n",
    "                          verbose=1,\n",
    "                          n_jobs=-1)\n",
    "\n",
    "#fit the grid\n",
    "grid_model.fit(X, y)\n",
    "\n",
    "\n",
    "# print the best parameters\n",
    "print(grid_model.best_params_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "25 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "23 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [       nan 0.96666667 0.96       0.96666667        nan        nan\n",
      " 0.96666667        nan        nan 0.96666667]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 200, 'max_features': 'sqrt', 'max_depth': 30, 'criterion': 'entropy'}\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "para_grid = {'n_estimators': [100, 200, 300, 400, 500],\n",
    "             'max_features': ['auto', 'sqrt', 'log2'],\n",
    "                'max_depth': [10, 20, 30, 40, 50],\n",
    "             'criterion': ['gini', 'entropy']\n",
    "             }\n",
    "\n",
    "# set up the grid\n",
    "grid_model = RandomizedSearchCV(model, \n",
    "                          para_grid, \n",
    "                          cv=5, \n",
    "                          scoring='accuracy',\n",
    "                          verbose=1,\n",
    "                          n_jobs=-1)\n",
    "\n",
    "#fit the grid\n",
    "grid_model.fit(X, y)\n",
    "\n",
    "\n",
    "# print the best parameters\n",
    "print(grid_model.best_params_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
