{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "\n",
    "Random Forest is a popular machine learning algorithm that belongs to the supervised learning technique. It can be used for both classification and regression tasks. It is also the most flexible and easy to use algorithm. A forest is comprised of trees. It is said that the more trees it has, the more robust a forest is. Random forests create decision trees on randomly selected data samples, get a prediction from each tree, and selects the best solution by means of voting. It also provides a pretty good indicator of the feature importance. \n",
    "\n",
    "\n",
    "A Random Forest is like a group decision-making team in machine learning. It combines the opinions of many “trees” (individual models) to make better predictions, creating a more robust and accurate overall model.\n",
    "\n",
    "\n",
    "### Benefits and challenges of random forest\n",
    "There are a number of key advantages and challenges that the random forest algorithm presents when used for classification or regression problems. Some of them include:\n",
    "\n",
    "#### Key Benefits\n",
    "\n",
    "1. Reduced risk of overfitting: Decision trees run the risk of overfitting as they tend to tightly fit all the samples within training data. However, when there’s a robust number of decision trees in a random forest, the classifier won’t overfit the model since the averaging of uncorrelated trees lowers the overall variance and prediction error.\n",
    "2. Provides flexibility: Since random forest can handle both regression and classification tasks with a high degree of accuracy, it is a popular method among data scientists. Feature bagging also makes the random forest classifier an effective tool for estimating missing values as it maintains accuracy when a portion of the data is missing.\n",
    "3. Easy to determine feature importance: Random forest makes it easy to evaluate variable importance, or contribution, to the model. There are a few ways to evaluate feature importance. Gini importance and mean decrease in impurity (MDI) are usually used to measure how much the model’s accuracy decreases when a given variable is excluded. However, permutation importance, also known as mean decrease accuracy (MDA), is another importance measure. MDA identifies the average decrease in accuracy by randomly permutating the feature values in oob samples.\n",
    "#### Key Challenges\n",
    "1. Time-consuming process: Since random forest algorithms can handle large data sets, they can be provide more accurate predictions, but can be slow to process data as they are computing data for each individual decision tree.\n",
    "2. Requires more resources: Since random forests process larger data sets, they’ll require more resources to store that data.\n",
    "3. More complex: The prediction of a single decision tree is easier to interpret when compared to a forest of them.\n",
    "\n",
    "\n",
    "![alt text](https://www.simplilearn.com/ice9/free_resources_article_thumb/Working_of_RF_1.png)\n",
    "\n",
    "\n",
    "The following steps explain the working Random Forest Algorithm:\n",
    "\n",
    "Step 1: Select random samples from a given data or training set.\n",
    "\n",
    "Step 2: This algorithm will construct a decision tree for every training data.\n",
    "\n",
    "Step 3: Voting will take place by averaging the decision tree.\n",
    "\n",
    "Step 4: Finally, select the most voted prediction result as the final prediction result.\n",
    "\n",
    "This combination of multiple models is called Ensemble. Ensemble uses two methods:\n",
    "\n",
    "#### Bagging: Creating a different training subset from sample training data with replacement is called Bagging. The final output is based on majority voting. \n",
    "\n",
    "#### Boosting: Combing weak learners into strong learners by creating sequential models such that the final model has the highest accuracy is called Boosting. \n",
    "Example: ADA BOOST, XG BOOST. \n",
    "\n",
    "![alt text](https://www.simplilearn.com/ice9/free_resources_article_thumb/Working_of_RF_2.png)\n",
    "\n",
    "\n",
    "#### Bagging:\n",
    " From the principle mentioned above, we can understand Random forest uses the Bagging code. Now, let us understand this concept in detail. Bagging is also known as Bootstrap Aggregation used by random forest. The process begins with any original random data. After arranging, it is organised into samples known as Bootstrap Sample. This process is known as Bootstrapping.Further, the models are trained individually, yielding different results known as Aggregation. In the last step, all the results are combined, and the generated output is based on majority voting. This step is known as Bagging and is done using an Ensemble Classifier.\n",
    "\n",
    "\n",
    " ![alt text](https://www.simplilearn.com/ice9/free_resources_article_thumb/Working_of_RF_3.png)\n",
    "\n",
    "\n",
    "### Essential Features of Random Forest\n",
    "`Miscellany:` Each tree has a unique attribute, variety and features concerning other trees. Not all trees are the same.\\\n",
    "`Immune to the curse of dimensionality:` Since a tree is a conceptual idea, it requires no features to be considered. Hence, the feature space is reduced.\\\n",
    "`Parallelization:` We can fully use the CPU to build random forests since each tree is created autonomously from different data and features.\\\n",
    "`Train-Test split:` In a Random Forest, we don’t have to differentiate the data for train and test because the decision tree never sees 30% of the data.\\\n",
    "`Stability:` The final result is based on Bagging, meaning the result is based on majority voting or average.\\\n",
    "\n",
    "Important Hyperparameters\n",
    "Hyperparameters are used in random forests to either enhance the performance and predictive power of models or to make the model faster. \n",
    "\n",
    "The following hyperparameters are used to enhance the predictive power:\n",
    "\n",
    "  * n_estimators: Number of trees built by the algorithm before averaging the products.\n",
    "  * max_features: Maximum number of features random forest uses before considering splitting a node.\n",
    "  * mini_sample_leaf: Determines the minimum number of leaves required to split an internal node.\n",
    "\n",
    "The following hyperparameters are used to increase the speed of the model:\n",
    "  * n_jobs: Conveys to the engine how many processors are allowed to use. If the value is 1, it can use only one processor, but if the value is -1,, there is no limit.\n",
    "  * random_state: Controls randomness of the sample. The model will always produce the same results if it has a definite value of random state and if it has been given the same hyperparameters and the same training data.\n",
    "  * oob_score: OOB (Out Of the Bag) is a random forest cross-validation method. In this, one-third of the sample is not used to train the data but to evaluate its performance. \n",
    "\n",
    "#### Important Terms to Know\n",
    "\n",
    "\n",
    "There are different ways that the Random Forest algorithm makes data decisions, and consequently, there are some important related terms to know. Some of these terms include:\n",
    "\n",
    "1. Entropy\n",
    "It is a measure of randomness or unpredictability in the data set.\n",
    "2. Information Gain\n",
    "A measure of the decrease in the entropy after the data set is split is the information gain.\n",
    "3. Leaf Node\n",
    "A leaf node is a node that carries the classification or the decision.\n",
    "4. Decision Node\n",
    "A node that has two or more branches.\n",
    "4. Root Node\n",
    "The root node is the topmost decision node, which is where you have all of your data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_bill</th>\n",
       "      <th>tip</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoker</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.99</td>\n",
       "      <td>1.01</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.34</td>\n",
       "      <td>1.66</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.01</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.68</td>\n",
       "      <td>3.31</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.59</td>\n",
       "      <td>3.61</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_bill   tip     sex smoker  day    time  size\n",
       "0       16.99  1.01  Female     No  Sun  Dinner     2\n",
       "1       10.34  1.66    Male     No  Sun  Dinner     3\n",
       "2       21.01  3.50    Male     No  Sun  Dinner     3\n",
       "3       23.68  3.31    Male     No  Sun  Dinner     2\n",
       "4       24.59  3.61  Female     No  Sun  Dinner     4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the tips dataset from sns\n",
    "df = sns.load_dataset('tips')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_bill</th>\n",
       "      <th>tip</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoker</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.99</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.34</td>\n",
       "      <td>1.66</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.01</td>\n",
       "      <td>3.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.68</td>\n",
       "      <td>3.31</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.59</td>\n",
       "      <td>3.61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_bill   tip  sex  smoker  day  time  size\n",
       "0       16.99  1.01    0       0    2     0     2\n",
       "1       10.34  1.66    1       0    2     0     3\n",
       "2       21.01  3.50    1       0    2     0     3\n",
       "3       23.68  3.31    1       0    2     0     2\n",
       "4       24.59  3.61    0       0    2     0     4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#encode features which are categorical or object using loop\n",
    "\n",
    "# encode features which are categorical or object using for loop\n",
    "le = LabelEncoder()\n",
    "for i in df.columns:\n",
    "    if df[i].dtype == 'object' or df[i].dtype == 'category':\n",
    "        df[i] = le.fit_transform(df[i])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score:  0.6122448979591837\n",
      "confusion matrix:\n",
      " [[ 7 12]\n",
      " [ 7 23]]\n",
      "classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.37      0.42        19\n",
      "           1       0.66      0.77      0.71        30\n",
      "\n",
      "    accuracy                           0.61        49\n",
      "   macro avg       0.58      0.57      0.57        49\n",
      "weighted avg       0.60      0.61      0.60        49\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# split the data into X and y for classification\n",
    "X = df.drop('sex', axis = 1)\n",
    "y = df['sex']\n",
    "# train test split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)\n",
    "# create, train and predict the mode\n",
    "model_cl = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "model_cl.fit(X_train, y_train)\n",
    "y_pred = model_cl.predict(X_test)\n",
    "\n",
    "#evaluate the model\n",
    "print('accuracy score: ', accuracy_score(y_test, y_pred))\n",
    "print('confusion matrix:\\n', confusion_matrix(y_test, y_pred))\n",
    "print('classification report:\\n', classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean squared error:  0.9384601810204097\n",
      "mean absolute error:  0.7745081632653065\n",
      "r2 score:  0.2492146443440324\n",
      "root mean squared error:  0.9687415450058956\n"
     ]
    }
   ],
   "source": [
    "# USe random Forest for Regression task\n",
    "X = df.drop('tip', axis = 1)\n",
    "y = df['tip']\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# train test split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)\n",
    "\n",
    "#create, train and predict the model\n",
    "model_reg = RandomForestRegressor()\n",
    "model_reg.fit(X_train, y_train)\n",
    "y_pred = model_reg.predict(X_test)\n",
    "\n",
    "# evaluate the model\n",
    "print('mean squared error: ', mean_squared_error(y_test, y_pred))\n",
    "print('mean absolute error: ', mean_absolute_error(y_test, y_pred))\n",
    "print('r2 score: ', r2_score(y_test, y_pred))\n",
    "print('root mean squared error: ', np.sqrt(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
